{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a0cff9",
   "metadata": {},
   "source": [
    "# 03 평가\n",
    "## 머신러닝의 프로세스 = \"데이터가공/변환\", \"모델 학습/예측\", \"평가\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90d1eb",
   "metadata": {},
   "source": [
    "## 머신러닝 모델의 예측 성능을 평가하는 성능 평가 지표(EvaluationMetric)\n",
    "는 일반적으로 모델이 분류냐 회귀냐에 따라 여러종류로 나뉜다.\n",
    "\n",
    "### 분류 : 실제 결과 데이터와 예측 결과데이터가 얼마나 정확하고 오류가 적게발생하는가에 기반하지만,\n",
    "  단순히 정확도만 가지고 판단할경우 잘못된 평가결과에 빠질수있다. \n",
    "      \n",
    "#### *분류( 결정 클래스값 종류의 유형에 따라 )\n",
    "   1) 이진분류 : 긍정/부정과 같은 2개의 결괏값만을 가짐\n",
    "   \n",
    "   2) 멀티분류 : 여러개의 결정 클래스값을 가짐\n",
    "   \n",
    "##### 아래의 6개의 분류성능지표는 이진/멀티 분류 모두에 적용되는 지표.\n",
    " \n",
    " ##### 특히 이진분류에서 더욱 중요하게 강조되는 지표이다\n",
    " \n",
    "      1) 정확도(Accuracy)\n",
    "      \n",
    "      2) 오차행렬(Confusion Matrix)\n",
    "      \n",
    "      3) 정밀도(Precision)\n",
    "      \n",
    "      4) 재현율(Recall)\n",
    "      \n",
    "      5) F1 스코어\n",
    "      \n",
    "      6) ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1d402",
   "metadata": {},
   "source": [
    " ### 회귀 : 대부분 실제값과 예측값의 오차평균값에 기반(5장에서 상세하게 설명)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b4976",
   "metadata": {},
   "source": [
    "## 01.정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcabbbb",
   "metadata": {},
   "source": [
    "### 정확도 : 실제데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d12eec",
   "metadata": {},
   "source": [
    "= ${예측결과가 동일한 데이터 건수 \\over 전체 예측 데이터 건수}$\n",
    "\n",
    "이는 직관적으로 모델예측성능을 나타내는 평가지표다.\n",
    "\n",
    "하지만, 이진 분류의 경우 ML모델의 성능을 왜곡할수있음.\n",
    "\n",
    "성능을 왜곡하는 예제를 살펴보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5f49f",
   "metadata": {},
   "source": [
    "타이타닉 예제에서 별다른 알고리즘 적용없이 무조건 성별이 여자인경우 생존으로 예측해도 비슷할수있다.\n",
    "\n",
    "단지 성별조건하나만을 가지고 결정하는 별거 아닌 알고리즘도 높은 정확도를 나타내는 상황이 발생하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b3436",
   "metadata": {},
   "source": [
    "#### 사이킷런 BaseEstimator클래스 상속받아 아무런 학습하지않고 성별에 따라 생존자를 예측하는 단순한 Classifier를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2766ac",
   "metadata": {},
   "source": [
    "##### 사이킷런은 BaseEstimator를 상속받으면 Customized형태의 Estimator를 개발자가 생성할수있다.\n",
    "##### 생성할 MyDummyClassifier클래스는 학습을 수행하는 fit()메서드는 아무런수행하지않으며, 예측을 수행하는 predict()메서드는 단순히  sex피쳐가 1이면0 으로 구분하는 단순한 classifier이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138211de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit()메서드는 아무것도 학습하지않음.\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    # predict()메서드는 단순히 sex피쳐가 1이면0, 그렇지 않으면 1로 예측함.\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19d723",
   "metadata": {},
   "source": [
    "이제 생성된 커스텀클래스를 이용해 타이타닉 생존자 예측 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1cd8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가공 내역 정리, 함수로 만들어 쉽게 재사용\n",
    "# 데이터 전처리를 전체적으로 호출하는 함수 transform_featurs(): null처리, 포매팅, 인코딩 수행 내부 함수로 구성\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48224a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는 : 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할.\n",
    "titanic_df = pd.read_csv(\"titanic_train.csv\")\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)  #전처리함수\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
    "\n",
    "#위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는 : {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cc938",
   "metadata": {},
   "source": [
    "#### 이렇게 단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도 결과는 약78.77%로  꽤 높은 수치가 나올수있기에 정확도를 평가 지표로 사용할 때는 매우 신중해야 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1e860",
   "metadata": {},
   "source": [
    "#### 특히, 정확도는 불균현항(imbalanced)레이블 값 분포에서 ML모델의 성능을 판단할 경우, 적합한 평가 지표가 아니다.\n",
    "#### 예를 들어, 100개의 데이터중에 90개 데이터 레이블이 0, 단 10개의 데이터 레이블이 1이라고한다면 무조건 0으로 예측결과를 반환하는 ML모델의 경우라도 정확도가 90%가 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531f4c2",
   "metadata": {},
   "source": [
    "#### 유명한 MNIST데이터세트를 변환해 불균형한 데이터 세트로 만든뒤에 정확도 지표 적용시 어떤 문제가 발생하는지 살펴보자\n",
    "MNIST설명 URL : https://sdc-james.gitbook.io/onebook/4.-and/5.1./5.1.3.-mnist-dataset\n",
    "\n",
    "MNIST데이터세트는 0부터9까지의 숫자 이미지의 픽셀 정보를 가지고있음.이를 기반으로 숫자Digit를 예측하는데 사용됨.\n",
    "\n",
    "사이킷런은 load_digits() API를 통해 제공한다.\n",
    "\n",
    "이것을 레이블값이 7인것만 True, 나머지는 모두 False로 변환하여 이진분류 문제로 변형해보자(즉, 전체 데이터의 10%만 True, 나머지 90%는 False인 불균형한 데이터 세트로 변형하는것)\n",
    "\n",
    "이렇게 불균형한 데이터 세트에 0으로 예측하는 classifier를 이용해 정확도를 측정하면 약90%에 가까운 예측 정확도를 나타낸다.\n",
    "\n",
    "**아무것도하지않고 무조건 특정한 결과로 찍어도 데이터 분포도가 균일하지 않은 경우 높은 수치가 나타날수있는 것이 정확도 평가지표의 맹점이다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa37cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불균형한 데이터 세트와 Dummy Classifier를 생성\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    #입력값으로 들어오는 X데이터세트의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "    \n",
    "    \n",
    "#사이킷런의 내장 데이터세트를 이용해 MNIST로딩\n",
    "digits = load_digits()\n",
    "\n",
    "#digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환.\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde42b8b",
   "metadata": {},
   "source": [
    "#### 다음으로 불균형한 데이터로 생성한 y_test의 데이터분포도를 확인하고 MyFakeClassifier를 이용해 예측과 평가를 수행해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e58d90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "#불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기 :' , y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "\n",
    "#dummy classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca0801",
   "metadata": {},
   "source": [
    "#### 이처럼 정확도 평가지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안됩니다.\n",
    "### 정확도가 가지는 분류 평가 지표로서 이러한 한계점을 극복하기 위해 여러가지 분류 지표와 함께 적용해야한다. 먼저 True/False, Positive/Negative의 4분면으로 구성되는 오차행렬(Confusion Matrix)에 대해 설명해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8daf0a",
   "metadata": {},
   "source": [
    "## 02.오차행렬(Confusion Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d292a75a",
   "metadata": {},
   "source": [
    "### 이진 분류에서 성능지표로 잘활용됨. 이진분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지 함께 나타내는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0524e3b",
   "metadata": {},
   "source": [
    "#### 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지를 나타냄."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb58ccb",
   "metadata": {},
   "source": [
    "<img src=\"confusionmatrix.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3fcbc",
   "metadata": {},
   "source": [
    "예측 클래스와 실제 클래스의 Positive결정값과 Negative결정값의 결합에 따라 결정됨.\n",
    "\n",
    "TN : 예측값을 Negative값0으로 예측했고 실제 값도 Negative 값 0 \n",
    "\n",
    "FP : 예측값을 Positive 값1로 예측했는데 실제 값은 Negative 값 0\n",
    "\n",
    "FN : 예측값을 Negative값0으로 예측했는데 실제 값은 Positive값1\n",
    "\n",
    "TP : 예측값을 Positive값1로 예측했는데 실제 값 역시 Positive값1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c128b68",
   "metadata": {},
   "source": [
    "사이킷런은 오차행렬을 구하기위헤 confusion_matrix() API를 제공합니다.\n",
    "\n",
    "정확도 예제에서 다룬 MyFakeClassifier의 예측 성능 지표를 오차 행렬로 표현해보자\n",
    "\n",
    "(MyFakeClassifier 예측결과인 fakepred와 실제 결과인 y_test를 인자로 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c69d7024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582ce7f",
   "metadata": {},
   "source": [
    "출력된 오차 행렬은 ndarray 형태\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdb392",
   "metadata": {},
   "source": [
    "일단, 예측을 무조건 negative(false)로 했기에 4분면중 오른쪽은 0건.\n",
    "\n",
    "모두 false이므로 false로 예측한 TN이 405개, 그중 45개만 true인데 false로 예측함.(FN=45개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb085a",
   "metadata": {},
   "source": [
    "##### TP,TN,FP,TN값은 Classifier성능의 여러 면모를 판단할 수 있는 기반 정보를 제공합니다. 이값을 조합해 Classifier의 성능을 측정할수있는 주요지표인 정확도(Accuracy), 정밀도(Precision), 재현율(Recall)값을 알수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac87b6",
   "metadata": {},
   "source": [
    "##### 정확도는 예측값과 실제값이 얼마나 동일한가에 대한 비율만으로 결정된다. 즉 , TN과 TP에 좌우된다.\n",
    "$정확도 = {(TN + TP) \\over ( TN + FP + FN + TP)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34661282",
   "metadata": {},
   "source": [
    "#### 일반적으로, 이진분류모델에서는 많은 데이터중에서 중점적으로 찾아야하는 매우 적은 수의 결괏값에 Positive를 설정해 1값을 부여하는 경우가 많음. 예를들어 사기행위예측모델에서는 사기행위가 Positive 양성으로 1, 정상행위가 Negative음성으로0값으로 설정하는 경우가 일반적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323d14c",
   "metadata": {},
   "source": [
    "##### 불균형한 이진 분류데이터세트에서는 Positive데이터 건수가 매우 작기때문에 데이터에 기반한 ML알고리즘은 positive보다 negative로 예측 정확도가 높아지는 경향이발생한다. TN은 매우커지고, TP는 매우작아짐. 또한 Negative로 예측할때 정확도가 높기 때문에 FN이 매우작고, FP역시 매우작아진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf3d3a",
   "metadata": {},
   "source": [
    "#### 결과적으로 정확도 지표는 비대칭한 데이터세트에서 Positive에 대한 예측 정확도를 판단하지 못한채 Negative에 대한 예측 정확도만으로도 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422423f",
   "metadata": {},
   "source": [
    "### 정확도는 분류모델의 성능을 측정할 수 있는 한 가지 요소일 뿐. 불균형한 데이터세트에서 정확도만으로는 모델 신뢰도가 떨어질수있는 사례를 보았으니, 다음으로는 불균형한데이터세트에서 정확도보다 더 선호되는 평가지표인 정밀도와 재현율에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6643b5",
   "metadata": {},
   "source": [
    "##### [참고]\n",
    "<img src='recall_precision.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63854f00",
   "metadata": {},
   "source": [
    "**민감도(sensitivity) = TP/(TP+FN) = 재현율(recall)**\n",
    "\n",
    "TP + FN : 전체 양성 개수\n",
    "\n",
    "TP : 양성으로 판정했는데 실제로 양성인 경우\n",
    "\n",
    "\n",
    "**특이도(specificity)=TN/(TN+FP)**\n",
    "\n",
    "TN + FP : 전체 음성 개수\n",
    "\n",
    "TN : 음성으로 판정했는데 실제로 음성인 경우\n",
    "\n",
    "\n",
    "#민감도와 특이도는 한 쪽이 증가하면 다른 한 쪽이 감소하는 경향을 보일 수 있습니다.\n",
    "\n",
    "예를 들어 검사 항목을 모두 양성으로 판정하면 민감도는 1이 되지만\n",
    "\n",
    "특이도는 0이 되며 반대로 모두 음성으로 판정하면 특이도는 1이 되지만 민감도는 0이 됩니다.\n",
    "\n",
    "궁극적으로는 민감도와 특이도가 둘 다 높게 나오는 방법을 찾아야 합니다.\n",
    "\n",
    "\n",
    "**정확도(accuracy) = (TP+TN) / (TP+FN+FP+TN)**\n",
    "\n",
    "전체 중에 양성과 음성을 맞춘 개수\n",
    "\n",
    "\n",
    "**정밀도(Precision) = (TP/TP+FP)**\n",
    "\n",
    "양성이라고 판정한 것 중에 실제 양성 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509a114",
   "metadata": {},
   "source": [
    "## 03.정밀도(Precision)와 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d1835",
   "metadata": {},
   "source": [
    "정밀도 : TP/TP+FP\n",
    "\n",
    "재현율(민감도) : TP/(TP+FN)\n",
    "\n",
    "### 정밀도 : 예측을 Positive로 한 대상 중, 예측과 실제 값이 Positive로 일치한 데이터의 비율 \n",
    "### 재현율 : 실제 값이 Positive인 대상 중, 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "\n",
    " - 참고: 정밀도는 Positive예측 성능을 더욱 정밀하게 측정하기위한 평가지표로 양성예측도 라고도 불린다\n",
    "\n",
    " - 재현율 = 민감도(Sensitivity) = TPR(True Positive Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c9364",
   "metadata": {},
   "source": [
    "#### 재현율 ~ 암판단모델, 금융사기(보험사기) 등 \n",
    "\n",
    "1) 실제 Positive양성 데이터를 Negative로 잘못판단하게되면 업무상 큰영향이 발생하는 경우\n",
    "\n",
    "   ex. 암환자(Positive)를 음성으로 판단할경우 생명위험. opp. 암이아닌데(negative) 양성으로 판단할경우 재검하면됨.\n",
    "\n",
    "   ex. 사기거래(Positive)를 Negative로 오판단할경우 회사손해.\n",
    "\n",
    "\n",
    "2) 보통 재현율이 정밀도 보다 상대적으로 중요한 업무가 많지만. 정밀도가 중요한 경우도있음.\n",
    "\n",
    "ex.스팸메일(positive)을 negative인 일반메일로 분류할경우 문제없음(사용자불편수준), 실제 일반메일(negative)을 positive(스팸메일)로 분류할경우 메일수신이 안되어 업무차질발생.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a08be",
   "metadata": {},
   "source": [
    "재현율과 정밀도 모두 TP를 높이는데 초점이맞추어져있으나,\n",
    "재현율은 FN(실제 P, 예측 N)을 낮추는데\n",
    "정밀도는 FP를 낮추는데 초점을 맞춤.\n",
    "\n",
    "모두 높은수치를 얻는것이 좋다. 반면에 둘중 한평가만 지표가 매우높고 다른하나는 매우 낮을 경우 바람직하지않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407b2c5",
   "metadata": {},
   "source": [
    "앞의 타이타닉에선 정확도에만 초점을 맞추었다면, 이번에 오차행렬 및 정밀도, 재현율을 모두 구하여 예측성능을 평가해보자\n",
    "사이킷런은 API를 제공한다(정밀도 precision_score(), 재현율 recall_score())\n",
    "\n",
    "평가의 편의를 위해 confusion matrix, accracy, precision, recall 등 한번에 호출하는 함수를 만들자. 그리고 타이타닉 데이터를 다시 로드하여 가공한 뒤 로지스틱 회귀로 분류를 수행하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93fb45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import(accuracy_score, precision_score, recall_score, confusion_matrix)\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도:{0:4f}, 정밀도:{1:.4f}, 재현율:{2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af5b5c",
   "metadata": {},
   "source": [
    "이제 로지스틱 회귀기반으로 타이타닉 생존자를 예측하고 confusion matrix, accuracy, precision, recall 평가를 수행합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de02efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#원본데이터를 재로딩, 데이터 가공, 학습 데이터/테그트 데이터 분할\n",
    "\n",
    "\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.20, random_state=11)\n",
    "lr_clf = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80b5ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도:0.849162, 정밀도:0.7742, 재현율:0.7869\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3133a93",
   "metadata": {},
   "source": [
    "### 정밀도/재현율 트레이드오프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5394d47",
   "metadata": {},
   "source": [
    "분류의 결정 임곗값(Threshold)을 조정하여 정밀도와 재현율 수치를 높일수 있다.\n",
    "\n",
    "하지만 상호보완적인 평가지표이기 때문에 한쪽을 높이면 다른쪽은 떨어지기쉽다 --> 이를 정밀도/재현율의 Trade-off라고한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfded023",
   "metadata": {},
   "source": [
    "사이킷런의 분류알고리즘은\n",
    "1) 예측데이터가 특정레이블(Lable,결정클래스값)에 속하는지를 계산하기위해 먼저 개별 레이블별로 결정확률을 구한다\n",
    "\n",
    "2) 예측확률이 큰 레이블값으로 예측하게 된다.\n",
    "\n",
    "ex) 0이될확률이 10%, 1이될 확률이 90%로 예측되면, 최종 예측은 더큰 확률을 가진 1로예측한다.\n",
    "\n",
    "일반적으로, 이진 분류에서는 이 임계값을 **0.5 즉 50%**로 정하고 이보다 크면 Positive,작으면 Negative로 결정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbaf3d",
   "metadata": {},
   "source": [
    "predict_proba() : 개별 데이터별로 예측확률을 반환하는 메서드\n",
    "\n",
    "테스트 피처 데이터세트를 주면 테스트 피처 레코드의 개별 클래스 예측확률을 반환\n",
    "\n",
    "cf. predict()와 유사. 반환결과가 예측결과 클래스값이 아닌 예측확률결과\n",
    "\n",
    "반환값 ndarray는 첫 번째 칼럼이 클래스값0에 대한 예측확률,\n",
    "\n",
    "두번째 칼럼이 클래스 값1에 대한 예측확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "007ed1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46216576 0.53783424]\n",
      " [0.8787286  0.1212714 ]\n",
      " [0.87716197 0.12283803]]\n",
      "두개의 class중에서 더큰 확률을 클래스 값으로 예측 \n",
      " [[0.46216576 0.53783424 1.        ]\n",
      " [0.8787286  0.1212714  0.        ]\n",
      " [0.87716197 0.12283803 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "#예측확률 array와 예측결괏값 array를 병합해 예측 확률과 결괏값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('두개의 class중에서 더큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79301933",
   "metadata": {},
   "source": [
    "첫번째 칼럼과 두번째 칼럼을 더하면 1이다.(예측확률을 반환함)\n",
    "\n",
    "두개의 칼럼중에서 더 큰 확률 값으로predict()메서드가 최종 예측하고있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88871ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
